# Extending the Autonomous Resource Acquisition Pipeline

This document provides guidance on how to extend and customize the resource acquisition pipeline for specific needs.

## Adding New Sources

To add new sources for the Scout Agent to monitor:

1. Update the `SOURCES` list in `scout_agent.py`
2. Or implement a database table for sources and modify the agent to read from it

Example:
```python
SOURCES = [
    "https://news.ycombinator.com/rss",
    "https://www.reddit.com/r/MachineLearning/.rss",
    "https://www.reddit.com/r/programming/.rss",
    "https://feeds.feedburner.com/oreilly/radar",
    "https://aws.amazon.com/blogs/aws/feed/",
    "https://cloud.google.com/feeds/blog.xml",
    "https://azurecomcdn.azureedge.net/en-us/blog/feed/",
    "https://www.docker.com/blog/feed/",
    "https://kubernetes.io/feed.xml",
    "https://your-custom-source.com/feed.xml",  # Add your new source here
]
```

## Adding New Opportunity Types

To add new opportunity types for classification:

1. Update the classification prompt in `classifier_agent.py`
2. Modify the validation logic to include the new types

Example:
```python
# In classifier_agent.py
classification_prompt = PromptTemplate(
    input_variables=["title", "content"],
    template="""
You are an AI assistant that classifies articles about technology opportunities.
Based on the title and content provided, classify the opportunity into one of the following categories:

1. FREE_TIER: Free service tiers or freemium offerings
2. TRIAL: Free trial offers or limited-time promotions
3. PARTNERSHIP_LEAD: Potential partnership opportunities or collaboration prospects
4. CONSULTING: Consulting or professional services opportunities
5. OTHER: Not relevant to our interests
# ... rest of the prompt
```

## Customizing Analysis Extraction

To customize what data is extracted during analysis:

1. Update the analysis prompt in `analysis_agent.py`
2. Modify the database schema if needed to accommodate new fields

Example:
```python
# In analysis_agent.py
analysis_prompt = PromptTemplate(
    input_variables=["title", "content", "opportunity_type"],
    template="""
# ... instructions ...
Respond in JSON format with the following structure:
{
  "provider_name": "Provider Name",
  "key_features": ["Feature 1", "Feature 2", "Feature 3"],
  "limitations": ["Limitation 1", "Limitation 2"],
  "contact_info": "Contact information",
  "pricing_details": "Pricing information",
  "support_options": ["Support option 1", "Support option 2"],  # New field
  "integration_complexity": "LOW|MEDIUM|HIGH",  # New field
  "summary": "Brief summary of the opportunity"
}
# ... rest of the prompt
```

## Adding New Actions in Partnership Agent

To add new actions in the Partnership Agent:

1. Add new conditions in the `process_message` function
2. Implement new functions for the specific actions

Example:
```python
# In partnership_agent.py
def process_message(ch, method, properties, body):
    
    # Add new action based on opportunity type or other criteria
    if opportunity_type == "CONSULTING":
        # Handle consulting opportunities
        success = handle_consulting_opportunity(opportunity_details)
    # ... rest of the code ...
```

## Customizing Integration Tasks

To customize the integration tasks generated by the Integration Planner Agent:

1. Update the integration prompt in `integration_planner_agent.py`
2. Modify the task generation logic if needed

Example:
```python
# In integration_planner_agent.py
integration_prompt = PromptTemplate(
    input_variables=["provider_name", "opportunity_type", "key_features", "api_key_available"],
    template="""
# ... instructions ...
The tasks should cover:
1. Creating an SDK for the new service (if it's a service with an API)
2. Adding the new service to the Budget Supervisor (if it has costs)
3. Updating agent tools with the new SDK
4. Configuring monitoring and alerting
5. Updating documentation
6. Creating example workflows  # New task type
# ... rest of the prompt
```

## Adding New Queues

To add new queues to the pipeline:

1. Add the new queue name to the environment variables
2. Update the `setup_rabbitmq.py` script
3. Create a new agent to consume from the queue
4. Update the docker-compose.yml and k8s-deployment.yaml files

Example:
```python
# In setup_rabbitmq.py
QUEUES = [
    os.getenv('RABBITMQ_RAW_NEWS_QUEUE', 'raw_news_queue'),
    os.getenv('RABBITMQ_PARSED_NEWS_QUEUE', 'parsed_news_queue'),
    os.getenv('RABBITMQ_CLASSIFIED_OPS_QUEUE', 'classified_ops_queue'),
    os.getenv('RABBITMQ_NEW_OPPORTUNITY_QUEUE', 'new_opportunity_queue'),
    os.getenv('RABBITMQ_INTEGRATION_PLANNING_QUEUE', 'integration_planning_queue'),
    os.getenv('RABBITMQ_CUSTOM_QUEUE', 'custom_queue')  # New queue
]
```

## Performance Optimization

To optimize performance:

1. Adjust the `prefetch_count` in agents to control concurrency
2. Implement batching for database operations
3. Add caching for frequently accessed data
4. Optimize the LLM prompts to reduce token usage
5. Implement rate limiting for external API calls

Example:
```python
# In any agent
# Adjust prefetch_count based on processing capacity
channel.basic_qos(prefetch_count=5)  # Process 5 messages at a time
```

## Monitoring and Alerting

To enhance monitoring:

1. Add custom metrics to each agent
2. Implement health check endpoints
3. Add structured logging
4. Integrate with monitoring systems like Prometheus
5. Set up alerting for critical failures

Example:
```python
# In any agent
import logging
from opentelemetry import metrics

# Set up custom metrics
meter = metrics.get_meter(__name__)
opportunity_counter = meter.create_counter(
    "opportunities.processed",
    description="Number of opportunities processed"
)

# Increment counter when processing opportunities
opportunity_counter.add(1, {"opportunity_type": opportunity_type})
```